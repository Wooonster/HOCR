{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å­¦æœ¯åŠ é€Ÿ\n",
    "\n",
    "å¦‚æœæ˜¯åœ¨ AutoDL ç§Ÿçš„æœåŠ¡å™¨ï¼Œä¸‹è½½æ¨¡å‹å‰è¿è¡Œä¸‹é¢ cell ä»¥è·å–å­¦æœ¯åŠ é€Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qwen2.5-VL-finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LENGTH = 8192\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id_3b = 'Qwen/Qwen2.5-VL-3B-Instruct-AWQ'\n",
    "model_id_7b = 'Qwen/Qwen2.5-VL-7B-Instruct-AWQ'\n",
    "save_dir_3b = './model/base/vl3b/'  # change to your save path\n",
    "save_dir_7b = './model/base/vl7b/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:834: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
      "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee0c018ef16f482f8ef130d87331b5a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 16 files:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/root/autodl-tmp/HOCR/finetune/model/base/vl7b'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "# snapshot_download(repo_id='Qwen/Qwen2.5-VL-3B-Instruct-AWQ', local_dir='./vl3b/', local_dir_use_symlinks=False)\n",
    "snapshot_download(repo_id=model_id_7b, local_dir=save_dir_7b, local_dir_use_symlinks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_7b' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(save_dir_7b)\n\u001b[1;32m     11\u001b[0m processor \u001b[38;5;241m=\u001b[39m AutoProcessor\u001b[38;5;241m.\u001b[39mfrom_pretrained(save_dir_7b)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mmodel_7b\u001b[49m\u001b[38;5;241m.\u001b[39menable_input_require_grads()   \u001b[38;5;66;03m# å¼€å¯æ¢¯åº¦æ£€æŸ¥ç‚¹æ—¶(training_args.gradient_checkpointing=True,)è¦æ‰§è¡Œè¯¥æ–¹æ³•\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_7b' is not defined"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor, AutoTokenizer\n",
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "\n",
    "model_7b = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    save_dir_7b, torch_dtype=torch.float16, trust_remote=True, \n",
    "    attn_implementation=\"flash_attention_2\"\n",
    ")\n",
    "model_7b.to(DEVICE)\n",
    "tokenizer = AutoTokenizer.from_pretrained(save_dir_7b)\n",
    "processor = AutoProcessor.from_pretrained(save_dir_7b)\n",
    "\n",
    "model_7b.enable_input_require_grads()   # å¼€å¯æ¢¯åº¦æ£€æŸ¥ç‚¹æ—¶(training_args.gradient_checkpointing=True,)è¦æ‰§è¡Œè¯¥æ–¹æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen2_5_VLForConditionalGeneration(\n",
      "  (visual): Qwen2_5_VisionTransformerPretrainedModel(\n",
      "    (patch_embed): Qwen2_5_VisionPatchEmbed(\n",
      "      (proj): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)\n",
      "    )\n",
      "    (rotary_pos_emb): Qwen2_5_VisionRotaryEmbedding()\n",
      "    (blocks): ModuleList(\n",
      "      (0-31): 32 x Qwen2_5_VLVisionBlock(\n",
      "        (norm1): Qwen2RMSNorm((1280,), eps=1e-06)\n",
      "        (norm2): Qwen2RMSNorm((1280,), eps=1e-06)\n",
      "        (attn): Qwen2_5_VLVisionFlashAttention2(\n",
      "          (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
      "          (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        )\n",
      "        (mlp): Qwen2_5_VLMLP(\n",
      "          (gate_proj): Linear(in_features=1280, out_features=3420, bias=True)\n",
      "          (up_proj): Linear(in_features=1280, out_features=3420, bias=True)\n",
      "          (down_proj): Linear(in_features=3420, out_features=1280, bias=True)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (merger): Qwen2_5_VLPatchMerger(\n",
      "      (ln_q): Qwen2RMSNorm((1280,), eps=1e-06)\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=5120, out_features=5120, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "        (2): Linear(in_features=5120, out_features=3584, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (model): Qwen2_5_VLModel(\n",
      "    (embed_tokens): Embedding(152064, 3584)\n",
      "    (layers): ModuleList(\n",
      "      (0-27): 28 x Qwen2_5_VLDecoderLayer(\n",
      "        (self_attn): Qwen2_5_VLFlashAttention2(\n",
      "          (q_proj): WQLinear_GEMM(in_features=3584, out_features=3584, bias=True, w_bit=4, group_size=128)\n",
      "          (k_proj): WQLinear_GEMM(in_features=3584, out_features=512, bias=True, w_bit=4, group_size=128)\n",
      "          (v_proj): WQLinear_GEMM(in_features=3584, out_features=512, bias=True, w_bit=4, group_size=128)\n",
      "          (o_proj): WQLinear_GEMM(in_features=3584, out_features=3584, bias=False, w_bit=4, group_size=128)\n",
      "          (rotary_emb): Qwen2_5_VLRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): WQLinear_GEMM(in_features=3584, out_features=18944, bias=False, w_bit=4, group_size=128)\n",
      "          (up_proj): WQLinear_GEMM(in_features=3584, out_features=18944, bias=False, w_bit=4, group_size=128)\n",
      "          (down_proj): WQLinear_GEMM(in_features=18944, out_features=3584, bias=False, w_bit=4, group_size=128)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "    (rotary_emb): Qwen2_5_VLRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_7b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ•°æ®é›†åŠ è½½ã€åˆ’åˆ†ã€æ˜ å°„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_func(example):\n",
    "    # print(f'example.ids: {example,keys()}'\n",
    "    input_ids, attention_mask, labels = [], [], []\n",
    "    url = example[\"message\"][0][\"conversation\"][0]['url']\n",
    "    caption = example[\"message\"][0][\"conversation\"][1]['caption']\n",
    "    \n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"You are a helpful assistant in recognize math equations in either handwritten or printed text.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\", \"text\": \"Recognize the equation in the image, write its LaTeX code between $$\\n and \\n$$\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    \"image\": url,\n",
    "                    \"resized_height\": 280,\n",
    "                    \"resized_width\": 280,\n",
    "                },\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": caption\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    text = processor.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    img_inputs, _ = process_vision_info(messages)\n",
    "    inputs = processor(\n",
    "        text=[text],\n",
    "        images=img_inputs,\n",
    "        padding=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    inputs = {key: value.tolist() for key, value in inputs.items()}\n",
    "    instruction = inputs\n",
    "    response = tokenizer(f'{caption}', add_special_tokens=False)\n",
    "    input_ids = (\n",
    "        instruction[\"input_ids\"][0] + response['input_ids'] + [tokenizer.pad_token_id]\n",
    "    )\n",
    "    attention_mask = instruction['attention_mask'][0] + response['attention_mask'] + [1]\n",
    "    labels = (\n",
    "        [-100] * len(instruction['input_ids'][0])\n",
    "        + response['input_ids']\n",
    "        + [tokenizer.pad_token_id]\n",
    "    )\n",
    "\n",
    "    if len(input_ids) > MAX_LENGTH:\n",
    "        input_ids = input_ids[:MAX_LENGTH]\n",
    "        attention_mask = attention_mask[:MAX_LENGTH]\n",
    "        labels = labels[:MAX_LENGTH]\n",
    "    \n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_mask = torch.tensor(attention_mask)\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    inputs['pixel_values'] = torch.tensor(inputs['pixel_values'])\n",
    "    # ç”± (1, h, w) å˜æ¢ä¸º (h, w)\n",
    "    inputs['image_grid_thw'] = torch.tensor(inputs['image_grid_thw']).squeeze(0)  \n",
    "    return {\n",
    "        \"input_ids\": input_ids, \n",
    "        \"attention_mask\": attention_mask, \n",
    "        \"labels\": labels,\n",
    "        \"pixel_values\": inputs['pixel_values'], \n",
    "        \"image_grid_thw\": inputs['image_grid_thw']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d624eb5076449e6a1ccbf5386925628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1019 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a14a44b0e04a5aace0d55859efb6b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/180 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ee6601048ca4cba9cfa3dc52fd5b666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1019 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'process_vision_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m dataset\u001b[38;5;241m.\u001b[39msave_to_disk(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/ft_dataset\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# save dataset\u001b[39;00m\n\u001b[1;32m     11\u001b[0m training_dataset, test_dataset \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m], dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 12\u001b[0m training_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess_func\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# mapping training dataset\u001b[39;00m\n\u001b[1;32m     14\u001b[0m training_dataset, test_dataset\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/datasets/arrow_dataset.py:562\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    555\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    560\u001b[0m }\n\u001b[1;32m    561\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 562\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    563\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/datasets/arrow_dataset.py:3079\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3074\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[1;32m   3075\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3076\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[1;32m   3077\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3078\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3079\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_single\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3080\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3081\u001b[0m \u001b[43m                \u001b[49m\u001b[43mshards_done\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/datasets/arrow_dataset.py:3495\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m batched:\n\u001b[1;32m   3494\u001b[0m     _time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m-> 3495\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miter_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard_iterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mupdate_data\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3497\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/datasets/arrow_dataset.py:3469\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.iter_outputs\u001b[0;34m(shard_iterable)\u001b[0m\n\u001b[1;32m   3467\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3468\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, example \u001b[38;5;129;01min\u001b[39;00m shard_iterable:\n\u001b[0;32m-> 3469\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m i, \u001b[43mapply_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/datasets/arrow_dataset.py:3392\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function\u001b[0;34m(pa_inputs, indices, offset)\u001b[0m\n\u001b[1;32m   3390\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Utility to apply the function on a selection of columns.\"\"\"\u001b[39;00m\n\u001b[1;32m   3391\u001b[0m inputs, fn_args, additional_args, fn_kwargs \u001b[38;5;241m=\u001b[39m prepare_inputs(pa_inputs, indices, offset\u001b[38;5;241m=\u001b[39moffset)\n\u001b[0;32m-> 3392\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prepare_outputs(pa_inputs, inputs, processed_inputs)\n",
      "Cell \u001b[0;32mIn[19], line 40\u001b[0m, in \u001b[0;36mpreprocess_func\u001b[0;34m(example)\u001b[0m\n\u001b[1;32m      7\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      8\u001b[0m     {\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     }\n\u001b[1;32m     35\u001b[0m ]\n\u001b[1;32m     37\u001b[0m text \u001b[38;5;241m=\u001b[39m processor\u001b[38;5;241m.\u001b[39mapply_chat_template(\n\u001b[1;32m     38\u001b[0m     messages, tokenize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     39\u001b[0m )\n\u001b[0;32m---> 40\u001b[0m img_inputs, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_vision_info\u001b[49m(messages)\n\u001b[1;32m     41\u001b[0m inputs \u001b[38;5;241m=\u001b[39m processor(\n\u001b[1;32m     42\u001b[0m     text\u001b[38;5;241m=\u001b[39m[text],\n\u001b[1;32m     43\u001b[0m     images\u001b[38;5;241m=\u001b[39mimg_inputs,\n\u001b[1;32m     44\u001b[0m     padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     45\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     46\u001b[0m )\n\u001b[1;32m     47\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {key: value\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems()}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'process_vision_info' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\" æ•°æ®é›†å‡†å¤‡ \"\"\"\n",
    "import json\n",
    "import random\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "dataset_dir = 'data/ft_data.json'\n",
    "dataset = load_dataset('json', data_files=dataset_dir)  # load dataset\n",
    "dataset = dataset['train'].train_test_split(test_size=0.15, shuffle=True, seed=5525)  # split\n",
    "dataset.save_to_disk('data/ft_dataset')  # save dataset\n",
    "\n",
    "training_dataset, test_dataset = dataset['train'], dataset['test']\n",
    "training_dataset = training_dataset.map(preprocess_func)  # mapping training dataset\n",
    "\n",
    "training_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### é¢„æµ‹ã€æµ‹è¯•å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_funcs import compute_bleu, compute_exprate\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def predict(messages, model):\n",
    "    # å‡†å¤‡æ¨ç†\n",
    "    text = processor.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    image_inputs, video_inputs = process_vision_info(messages)\n",
    "    inputs = processor(\n",
    "        text=[text],\n",
    "        images=image_inputs,\n",
    "        videos=video_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    inputs = inputs.to(model.device)\n",
    "\n",
    "    # ç”Ÿæˆè¾“å‡º\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=128)\n",
    "    generated_ids_trimmed = [\n",
    "        out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    output_text = processor.batch_decode(\n",
    "        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "    )\n",
    "\n",
    "    return output_text[0]\n",
    "\n",
    "def test_results(dataset, model, return_list=False):\n",
    "    # test_dataset = dataset['test']\n",
    "    test_outputs = defaultdict(list)\n",
    "    swan_list = []\n",
    "    \n",
    "    for item in dataset:\n",
    "        url = item[\"message\"][0][\"conversation\"][0]['url']\n",
    "        caption = item[\"message\"][0][\"conversation\"][1]['caption']\n",
    "        # Create the conversation prompt\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\", \n",
    "                \"content\": \"You are a helpful assistant in recognizing math equations in either handwritten or printed text.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": \"Recognize the equation in the image, write its LaTeX code between $$\\\\t and \\\\t$$\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        \"image\": url,\n",
    "                        \"resized_height\": 280,\n",
    "                        \"resized_width\": 280,\n",
    "                    },\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "        # Generate a prediction using the model\n",
    "        response = predict(messages, model)\n",
    "        # Save the prediction keyed by image URL\n",
    "        test_outputs[url] = [response, caption]\n",
    "        swan_list.append(swanlab.Image(url, caption=response)\n",
    "        \n",
    "    # Compute evaluation metrics\n",
    "    compute_bleu(test_outputs)\n",
    "    compute_exprate(test_outputs)\n",
    "    \n",
    "    return swan_list if return_list else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### é…ç½® LoRA å‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, TaskType, get_peft_model, PeftModel\n",
    "\n",
    "# é…ç½®LoRA\n",
    "config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    inference_mode=False,  # è®­ç»ƒæ¨¡å¼\n",
    "    r=8,  # Lora ç§©\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,  # Dropout æ¯”ä¾‹\n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "# è·å–LoRAæ¨¡å‹\n",
    "peft_model_7b = get_peft_model(model_7b, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### é…ç½®é¢„è®­ç»ƒå‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Qwen2VLForConditionalGeneration,\n",
    "    AutoProcessor,\n",
    ")\n",
    "\n",
    "# é…ç½®è®­ç»ƒå‚æ•°\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./model/output/Qwen2.5-VL-7B-ft/\",\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    per_device_train_batch_size=4,  # total batch size = per_device_train_batch_size * gradient_accumulation_steps\n",
    "    gradient_accumulation_steps=4,\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=25,\n",
    "    logging_first_step=True,\n",
    "    num_train_epochs=3,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=1e-4,\n",
    "    lr_scheduler_type='cosine',\n",
    "    save_on_each_node=True,\n",
    "    gradient_checkpointing=True,\n",
    "    report_to=\"none\",\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¦‚æœæƒ³è®°å½•ä¸‹è®­ç»ƒå¯è§†åŒ–æ•°æ®ï¼Œå¯ä»¥ç”¨ swanlabï¼Œæ²¡æœ‰åœ¨ä¸‹é¢ Trainer é‡ŒæŠŠ `callbacks=[swanlab_callback],  # æ²¡æœ‰æ³¨é‡Šå³å¯` æ³¨é‡Šå³å¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import swanlab\n",
    "from swanlab.integration.transformers import SwanLabCallback\n",
    "\n",
    "# è®¾ç½®SwanLabå›è°ƒ\n",
    "swanlab_callback = SwanLabCallback(\n",
    "    project=\"Qwen2.5-VL-7b-finetune-2\",\n",
    "    experiment_name=\"qwen2.5-vl-crohme2019\",\n",
    "    config={\n",
    "        \"model\": \"https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct-AWQ\",\n",
    "        \"dataset\": \"https://disk.pku.edu.cn/anyshare/en-us/link/AAF10CCC4D539543F68847A9010C607139?_tb=none&expires_at=1970-01-01T08%3A00%3A00%2B08%3A00&item_type=&password_required=false&title=HMER%20Dataset&type=anonymous\",\n",
    "        \"github\": \"https://github.com/Wooonster/HOCR\",\n",
    "        \"prompt\": \"Recognize the equation in the image, write its LaTeX code bettwen $$\\t and \\t$$\",\n",
    "        \"train_data_number\": len(train_dataset),\n",
    "        \"lora_rank\": 8,\n",
    "        \"lora_alpha\": 16,\n",
    "        \"lora_dropout\": 0.1,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¼€å§‹è®­ç»ƒï¼Œå¹¶ä¸”ç¨³å®šåï¼Œåœ¨ç»ˆç«¯ `watch -n 1 nvidia-smi` è§‚æµ‹ä¸€ä¸‹ GPU æ˜¾å­˜å ç”¨æƒ…å†µï¼Œå¯ä»¥è®°å½•ä¸€ä¸‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='201' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 11/201 01:15 < 26:27, 0.12 it/s, Epoch 0.15/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mswanlab\u001b[0m\u001b[0m: Step 1 on key train/loss already exists, ignored.\n",
      "\u001b[1m\u001b[33mswanlab\u001b[0m\u001b[0m: Step 1 on key train/grad_norm already exists, ignored.\n",
      "\u001b[1m\u001b[33mswanlab\u001b[0m\u001b[0m: Step 1 on key train/learning_rate already exists, ignored.\n",
      "\u001b[1m\u001b[33mswanlab\u001b[0m\u001b[0m: Step 1 on key train/epoch already exists, ignored.\n"
     ]
    }
   ],
   "source": [
    "# é…ç½®Trainer\n",
    "trainer = Trainer(\n",
    "    model=peft_model_7b,\n",
    "    args=args,\n",
    "    train_dataset=training_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),\n",
    "    callbacks=[swanlab_callback],  # æ²¡æœ‰æ³¨é‡Šå³å¯\n",
    ")\n",
    "\n",
    "# å¼€å¯æ¨¡å‹è®­ç»ƒ\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_7b' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 15\u001b[0m\n\u001b[1;32m      4\u001b[0m val_config \u001b[38;5;241m=\u001b[39m LoraConfig(\n\u001b[1;32m      5\u001b[0m     task_type\u001b[38;5;241m=\u001b[39mTaskType\u001b[38;5;241m.\u001b[39mCAUSAL_LM,\n\u001b[1;32m      6\u001b[0m     target_modules\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq_proj\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk_proj\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv_proj\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mo_proj\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgate_proj\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mup_proj\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdown_proj\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# è·å–æµ‹è¯•æ¨¡å‹\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m val_peft_model \u001b[38;5;241m=\u001b[39m PeftModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[43mmodel_7b\u001b[49m, model_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./output/Qwen2-VL-7B/checkpoint-134\u001b[39m\u001b[38;5;124m\"\u001b[39m, config\u001b[38;5;241m=\u001b[39mval_config)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_7b' is not defined"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, TaskType, get_peft_model, PeftModel\n",
    "\n",
    "# é…ç½®æµ‹è¯•å‚æ•°\n",
    "val_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    inference_mode=True,  # è®­ç»ƒæ¨¡å¼\n",
    "    r=8,  # Lora ç§©\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,  # Dropout æ¯”ä¾‹\n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "# è·å–æµ‹è¯•æ¨¡å‹\n",
    "val_peft_model = PeftModel.from_pretrained(model_7b, model_id=\"./output/Qwen2-VL-7B/checkpoint-134\", config=val_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv3d(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': '$$x = x_a - x_b$$'}\n",
      "{'role': 'assistant', 'content': '$$a=1...7$$'}\n",
      "{'role': 'assistant', 'content': '$$x+u$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\sqrt{1 + z^2}$$'}\n",
      "{'role': 'assistant', 'content': '$$C_{t}=K$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\text{and } \\\\text{one goes down from } m$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\frac{1}{\\\\epsilon}\\\\int_{-\\\\infty}^{\\\\infty}dz$$'}\n",
      "{'role': 'assistant', 'content': '$$a b - a ^ { - 2 } b ^ { - 2 }$$'}\n",
      "{'role': 'assistant', 'content': '$$b_{m}=\\\\lim _{a\\\\to 0}{\\\\frac {b_{m}-a}{a}}$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\Delta ^ { \\\\prime } ( m ) = 8 x - \\\\frac { 1 } { 6 } ( m + 1 ) ( m + 2 ) ( m + 3 )$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\sqrt{\\\\frac{R}{n}}$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\frac{-4}{\\\\sqrt{360}}$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\sqrt{-8}$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\lim_{R \\\\to 0} k^2 G(R) = \\\\infty$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\int d^dx e(x)$$'}\n",
      "{'role': 'assistant', 'content': '$$c(\\\\omega)=\\\\sum_{n}c_n\\\\omega^{n+1}$$'}\n",
      "{'role': 'assistant', 'content': '$$\\txyt\\t$$'}\n",
      "{'role': 'assistant', 'content': \"$$\\\\tan \\\\alpha \\\\tan \\\\theta' = 1$$\"}\n",
      "{'role': 'assistant', 'content': '$$Z = x^{2 + 2} + i x^{4 + 3}$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\lim_{p \\\\to \\\\infty} u(|\\\\rho|) = \\\\infty$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\left(n+1\\\\right)\\\\times \\\\left(n+1\\\\right)\\\\times \\\\ldots \\\\times \\\\left(n+1\\\\right)$$'}\n",
      "{'role': 'assistant', 'content': '$$A=\\\\int d\\\\alpha A(\\\\alpha)\\\\sum_{j}B_{j}(\\\\alpha)B_{j}(\\\\alpha)$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\sqrt{2+\\\\frac{a^{*}}{x^{4}}}>1$$'}\n",
      "{'role': 'assistant', 'content': '$$0 > n > -1$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\sin \\\\alpha = 0$$'}\n",
      "{'role': 'assistant', 'content': '$$-2\\\\log \\\\left(\\\\cos \\\\left(\\\\frac{1}{2}mz\\\\right)\\\\right)$$'}\n",
      "{'role': 'assistant', 'content': '$$\\t\\\\sqrt{k}x^2\\t$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\chi = \\\\chi _ { D } = 2 + \\\\sqrt { 3 }$$'}\n",
      "{'role': 'assistant', 'content': '$$a=3\\\\left(4+\\\\sqrt{10}\\\\right)\\\\sqrt{10}/5+14\\\\sqrt{10}$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\sin L t$$'}\n",
      "{'role': 'assistant', 'content': '$$8cos\\\\theta$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\int c_{z}$$'}\n",
      "{'role': 'assistant', 'content': '$$- \\\\frac { 1 } { 2 \\\\sqrt { 3 } }$$'}\n",
      "{'role': 'assistant', 'content': '$$-cos\\\\theta$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\int_{d_{c}}$$'}\n",
      "{'role': 'assistant', 'content': '$$f(t)=\\\\sum_{n=1}^{\\\\infty}a_{n}t^{n}$$'}\n",
      "{'role': 'assistant', 'content': '$$B=\\\\int_{0}^{\\\\kappa}\\\\mathrm{d}\\\\kappa\\\\int_{\\\\kappa_{a}}^{\\\\kappa}\\\\mathrm{d}\\\\kappa\\\\int_{\\\\kappa_{b}}^{\\\\kappa_{cd}}\\\\mathrm{d}\\\\beta F(\\\\gamma_{3})$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\Phi(y)=1-\\\\frac{1}{4}y^{2}-\\\\frac{1}{16}y^{4}\\\\log y+...$$'}\n",
      "{'role': 'assistant', 'content': '$$z=x^{8}+ix^{9}$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\cos ( u )$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\lim_{x \\\\to \\\\infty} \\\\phi(x) = \\\\phi^0$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\sin x_{i}, \\\\cos x_{i}$$'}\n",
      "{'role': 'assistant', 'content': '$$x^{2}+y^{2}=n^{2}+\\\\alpha^{2}$$'}\n",
      "{'role': 'assistant', 'content': '$$F = \\\\frac{1}{4} F_{ab} F^{ab}$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\beta^{m}+\\\\beta^{-m}-2$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\sqrt{4m}$$'}\n",
      "{'role': 'assistant', 'content': '$$T = \\\\lim_{u \\\\to \\\\infty} u g_u$$'}\n",
      "{'role': 'assistant', 'content': '$$\\t+ \\\\sqrt{\\\\rho - 1} \\t$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\left( {+ \\\\frac{1}{2} + \\\\frac{1}{2}, + \\\\frac{1}{2}, - \\\\frac{1}{2}, + \\\\frac{1}{2}} \\\\right)$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\left[ \\\\alpha _ { l } ^ { x } , \\\\alpha _ { l } ^ { y } \\\\right] = \\\\alpha ^ { 2 ( x - y ) }$$'}\n",
      "{'role': 'assistant', 'content': '$$4(n+1)-3n-n=4$$'}\n",
      "{'role': 'assistant', 'content': '$$\\t(-x)^{-a} \\\\log x \\t$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\sqrt{ab}$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\int_{a}^{b}dx f(x)e^{inx}$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\gamma = \\\\tan^2 t$$'}\n",
      "{'role': 'assistant', 'content': '$$\\t(x, y) = M(\\\\cos (\\\\alpha), \\\\sin (\\\\alpha)) \\t$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\log \\\\sqrt{2} \\\\pi$$'}\n",
      "{'role': 'assistant', 'content': '$$j_2 = -\\\\left(\\\\frac{m}{2}+1\\\\right)-\\\\left(\\\\frac{m}{2}+\\\\frac{1}{2}\\\\right)k^{-2}$$'}\n",
      "{'role': 'assistant', 'content': '$$x^{7}-x^{8}$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\cos(my)$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\frac { n } { 2 } + \\\\frac { m } { 2 } b ^ { - 2 }$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\alpha (1 - \\\\cos r)$$'}\n",
      "{'role': 'assistant', 'content': '$$T(x)=iu\\\\sin(x)$$'}\n",
      "{'role': 'assistant', 'content': '$$x - r$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\sin ^{2}x$$'}\n",
      "{'role': 'assistant', 'content': '$$2\\\\pi(\\\\sin \\\\theta_{1}+\\\\sin \\\\theta_{2})$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\left(\\\\frac{\\\\rho\\\\Omega^{-\\\\rho}}{1+\\\\rho}+1\\\\right)$$'}\n",
      "{'role': 'assistant', 'content': '$$a x + b y = 0$$'}\n",
      "{'role': 'assistant', 'content': '$$y^{\\\\prime}=4x^{3}+Ax+B$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\left(a+b+c\\\\right)$$'}\n",
      "{'role': 'assistant', 'content': '$$n\\\\log n$$'}\n",
      "{'role': 'assistant', 'content': '$$5 - x = 7$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\frac{646}{9}$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\beta^{(3)} = - \\\\frac{17}{3} \\\\frac{1}{(4 \\\\pi)^3}$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\left( xy \\\\right) ^ { - 1 } = y ^ { - 1 } x ^ { - 1 }$$'}\n",
      "{'role': 'assistant', 'content': '$$2 n + 2 - ( n - 1 ) = n + 3$$'}\n",
      "{'role': 'assistant', 'content': '$$f(x) = \\\\alpha_{ab} x^a x^b$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\tan \\\\theta = f$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\frac{i}{r+i}=1-\\\\frac{k}{rti}$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\lambda > 3 \\\\times 2 + 1 = 7$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\sin \\\\theta _ { 1 } \\\\sin \\\\theta _ { 2 } \\\\sin \\\\theta _ { 3 } \\\\sin \\\\theta _ { 4 }$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\lim_{z \\\\to \\\\infty} z S(z)$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\text{for any root}$$'}\n",
      "{'role': 'assistant', 'content': '$$P_{2}(x)=(x-a)(x-b)$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\Delta y = qy \\\\Delta x$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\lim_{d \\\\rightarrow \\\\infty} (R_{ab} - \\\\frac{1}{2} R_{a0} d) / (Cd - 2)$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\beta = c$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\lim \\\\sqrt{x}$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\tan \\\\beta = 2$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\frac{1}{2}n(n+3)+3$$'}\n",
      "{'role': 'assistant', 'content': '$$137 - 3 + 7 + 137 = ( 2 ^ { 3 } - 4 ) + ( 2 ^ { 3 } - 4 ) + ( 2 ^ { 3 } - 4 )$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\forall i, k$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\cos f(0)=\\\\cos f(\\\\pi)=\\\\pm1$$'}\n",
      "{'role': 'assistant', 'content': '$$AdS_{3}\\\\times S^{3}\\\\times S^{3}\\\\times S^{1}$$'}\n",
      "{'role': 'assistant', 'content': '$$x^{a} x^{b}$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\int f(x) \\\\, dx$$'}\n",
      "{'role': 'assistant', 'content': '$$-\\\\sqrt{2}$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\frac{1}{2} \\\\cos 2 \\\\alpha$$'}\n",
      "{'role': 'assistant', 'content': '$$y = y_b - y_a$$'}\n",
      "{'role': 'assistant', 'content': '$$a = 3 \\\\left( 4 - \\\\sqrt { 1 0 } \\\\right) \\\\sqrt { 5 } / \\\\left( 1 4 0 \\\\sqrt { 1 0 } - 5 \\\\right)$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\frac{-3}{\\\\sqrt{360}}$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\left( (a+b+\\\\ldots+c) \\\\right)^{2} \\\\geq a^{2}+b^{2}+\\\\ldots+c^{2}$$'}\n",
      "{'role': 'assistant', 'content': '$$a[3]=\\\\frac{1}{2}a_{2}+a_{3}+\\\\frac{3}{2}$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\cos ( n z )$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\lim_{x \\\\rightarrow + \\\\infty} u^{\\\\prime} v^{\\\\prime} = + \\\\infty$$'}\n",
      "{'role': 'assistant', 'content': '$$H_{n}=\\\\sum\\\\limits_{j}a_{j}^{n-1}b_{j}$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\Sigma_{n}\\\\leq n,\\\\Sigma_{m}\\\\leq m$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\frac{1}{x + i \\\\alpha}$$'}\n",
      "{'role': 'assistant', 'content': '$$y = \\\\tan ( z )$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\sin ^{2}u$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\frac { 1 } { 2 } - \\\\sin ^ { 2 } \\\\alpha$$'}\n",
      "{'role': 'assistant', 'content': '$$a = \\\\sqrt{\\\\frac{1 + \\\\sqrt{1 + 12\\\\varphi}}{6\\\\varphi}}$$'}\n",
      "{'role': 'assistant', 'content': '$$\\tn \\\\times n'}\n",
      "{'role': 'assistant', 'content': '$$\\\\tan \\\\beta = 80$$'}\n",
      "{'role': 'assistant', 'content': '$$\\t(1)+(12)+(11)+(12)+(123) \\t$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\frac{325}{66}$$'}\n",
      "{'role': 'assistant', 'content': '$$x^{5}-x^{3}$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\frac{3}{4} = - \\\\frac{1}{2} ( \\\\frac{1}{2} + n )$$'}\n",
      "{'role': 'assistant', 'content': '$$\\\\frac{e}{\\\\sqrt{2 \\\\pi}}$$'}\n",
      "\u001b[1m\u001b[33mswanlab\u001b[0m\u001b[0m: List length 'Prediction' is too long, cut to 108.\n",
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: ğŸŒŸ Run `\u001b[1mswanlab watch /root/autodl-tmp/HOCR/finetune/swanlog\u001b[0m` to view SwanLab Experiment Dashboard locally\n",
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: ğŸ  View project at \u001b[34m\u001b[4mhttps://swanlab.cn/@Wonster/Qwen2.5-VL-7b-finetune\u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://swanlab.cn/@Wonster/Qwen2.5-VL-7b-finetune/runs/1jxoubmr2r64w1ax2usme\u001b[0m\u001b[0m\n",
      "                                                                                                    \r"
     ]
    }
   ],
   "source": [
    "swan_list = test_results(test_dataset, val_peft_model, return_list=True)  # æ²¡æœ‰ swanlab, return_list=False\n",
    "if swan_list is not None:\n",
    "    swanlab.log({\"Prediction\": swan_list})\n",
    "    # åœ¨ Jupyter Notebook ä¸­è¿è¡Œæ—¶è¦åœæ­¢SwanLabè®°å½• éœ€è¦è°ƒç”¨swanlab.finish()\n",
    "    swanlab.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
